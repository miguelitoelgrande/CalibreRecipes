#!/usr/bin/env  python2

__license__   = 'GPL v3'
__copyright__ = '2015, MM'

'''
Install and use Firefox and its Calibre plugin
Run the "Tools->Output as HTML" in ScapBook before using this feed recipe
!!!Take the URL from the displayed HTML index and adapt below!!!
'''

import re
#from calibre import strftime
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import Tag


class ScrapBook2Calibre(BasicNewsRecipe):
    title                 = 'ScrapBook2Calibre'
    __author__            = 'MM'
    description           = 'Create an eBook from Firefox plugin Calibre'
    publisher             = 'ScrapBook'
    category              = 'knowledge'
    no_stylesheets        = False
#    encoding              = 'utf-8'
    use_embedded_content  = False
#    language = 'en'
    lang                  = 'en'
    
    remove_empty_feeds = True
    remove_javascript = True

    #MM: added those two as a quick win improvement.
    ignore_duplicate_articles = {'title', 'url'}
    simultaneous_downloads = 6
    
    INDEX    = u'file:///C:/Users/michael/AppData/Roaming/Mozilla/Firefox/Profiles/cmjoai5n.default/ScrapBook/tree/index.html'
    BASE_URL = u'file:///C:/Users/michael/AppData/Roaming/Mozilla/Firefox/Profiles/cmjoai5n.default/ScrapBook/tree/'

#    INDEX    = u'file:///C:/Users/user/AppData/Roaming/Mozilla/Firefox/Profiles/rnp74k3y.default/ScrapBook/tree/index.html'
#    BASE_URL = u'file:///C:/Users/user/AppData/Roaming/Mozilla/Firefox/Profiles/rnp74k3y.default/ScrapBook/tree/'
   
    extra_css = '''
          table td { border: 1px solid rgb(170, 170, 170); background-color: rgb(249, 249, 249); padding: 5px; font-size: 95%; }  
          .noprint, div#jump-to-nav, .mw-jump, div.top, div#column-one, #colophon, .mw-editsection, .mw-editsection-like, .toctoggle, #toc.tochidden, div#f-poweredbyico, div#f-copyrightico, li#about, li#disclaimer, li#mobileview, li#privacy, #footer-places, .mw-hidden-catlinks, tr.mw-metadata-show-hide-extended, span.mw-filepage-other-resolutions, #filetoc, .usermessage, .patrollink, .ns-0 .mw-redirectedfrom, #mw-navigation, #siteNotice { display: none; }
                '''
                
#             body{font-family:verdana,arial,helvetica,geneva,sans-serif;}

    conversion_options = {'comments': description, 'tags': category, 'language': lang
                        , 'publisher': publisher
                        , 'linearize_tables': False  # important! Want to keep (real) tables in text!
                        , 'filter_css': u'font-family,width,height,-webkit-column-width,min-width,min-height' # if we stick to original CSS and table structures, we need                  to get rid of fixed width, etc.                        
#                        , 'base_font_size' : 11.0,
                        }

    # the tables with fixed width/height may be a problem...
    remove_attributes=['width','height','lang']

# linearize-tables
# 
# Some badly designed documents use tables to control the layout of text on the page.
# When converted these documents often have text that runs off the page and other artifacts.
# This option will extract the content from the tables and present it in a linear fashion.

# pretty-print
# 
# If specified, the output plugin will try to create output that is as human readable as possible.
# May not have any effect for some output plugins.

# output-profile   kindle, kindle_dx, kindle_fire, kindle_pw,



#    keep_only_tags = [         
#         #dict(name='div', attrs={'id':'srodek','class':'kolumna'}) 
#		 #dict(name='table', attrs={'class':'contentpaneopen'}) 
#    ]
        
      
    
    remove_tags = [
              dict( attrs={'class':re.compile( '^.*noprint.*$', re.IGNORECASE)}), # Wikipedia CSS, fields like "[Edit]" will be removed
#                   dict( attrs={'class':lambda x: x and 'noprint' in x.split()} )  # Wikipedia CSS, fields like "[Edit]" will be removed
#                    dict(attrs={'class':'noprint'}) # Wikipedia CSS, fields like "[Edit]" will be removed
#                 ,    dict(name='div', attrs={'class':'yvComment'}) 
                  ]


    def parse_index(self):
        soup = self.index_to_soup(self.INDEX)
        index = []
        folder = 'main' # if no folder at all...

        elist = soup.find('ul', attrs = {'id': 'folder-root'})
        articles = []
        # need the other td tags which are NOT the right aligned numberings... 
        #  and not tag.has_key('align')   and not tag['align'] == 'right'
        for li in elist.findAll(lambda tag: tag.name == 'li' and len(tag.attrs) <> 0  ):
            #NEW: reproducing the ScrapBooks folders in Calibre as feeds...
            a = li.a
            if a is not None : # separators just have <hr>, no a-Tag
                a.extract()            
                title = self.tag_to_string(a) 
                url =  a['href']   
                if a['class'] == 'folder' :  # set folder name
                   if len(articles) <> 0:
                       index.append((folder, articles))
                       articles = []
                   folder = self.tag_to_string(a)       
                if url[:11] <> 'javascript:' :  # avoid links: javascript:toggle('folder-xxxx');            
                    url = self.BASE_URL + url
                    description = self.tag_to_string(a)                 
                    articles.append({'title': title
                                  #  , 'date': None
                                    , 'url': url
                                  #  , 'description' : description
                                    })
        index.append((folder, articles))

        return index



